{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from preprocess_functions import preprocess #preprocess is a class containing all the function, not sure why I made it a class\n",
    "#May have to specify the location of the preprocess_functions files relative to this one\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Finding the right files\n",
    "First it can be useful to locate and save the path to several fluorescence files at once, but One can also just do it one by one. \n",
    "For now, the code in preprocess_functions.py is built around the flourescence.csv file. However, this will soon be changed, as I have discovered that it is aligned to the isosbestic frame, which I'm not using, and the timestamps for the events are therefore not perfectly aligned. \n",
    "\n",
    "But for now, here's a way to use os.walk to get several files at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rootdir = '/Volumes/RanczLab/Photometry_recordings/August_Mismatch_Experiment_G8m/MM_closed-and-open_day2/' #path to the folder in which you hav all the recordings\n",
    "\n",
    "paths=[]\n",
    "for dirpath, subdirs, files in os.walk(rootdir): #This walks through the folders and files\n",
    "    for x in files:\n",
    "        if x == 'Fluorescence.csv': #if the file in a folder has this name, we save its path to a list of paths\n",
    "            paths.append(os.path.join(dirpath))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths = ['/Volumes/RanczLab/Photometry_recordings/August_Mismatch_Experiment_GRAB/B3M8_MMclosed_and_Regular_day1/2024_08_22-13_34_31/']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Applying the relevant preprocessing functions\n",
    "Have a look at the printed text. Ensure that the mouse ID is correct. If you have a different way of naming the files and, the code will need to be adjusted. \n",
    "\n",
    "For now, it uses the folder name to get the mouse ID and the experiment name.\n",
    "\n",
    "It asks for the sex of the animal and the location of the fiber. I usually write M or F for the sex, and V2M or V1 for the location. Whatever you do name it, it's best to be consistent to make the data analysis better. \n",
    "\n",
    "First, lets do it one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = paths[-2] #selecting a random path\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Assign cutoff frequencies for butterworth filter\n",
    "\n",
    "Filtering is done using function: https://docs.scipy.org/doc/scipy-1.15.0/reference/generated/scipy.signal.butter.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting a Wn. Make a dict where Wns are assigned to \n",
    "Wns = {'470':3, '560':25, '410':3}\n",
    "\n",
    "# Now create an object which will contain an increasing amount of information as functions are called on\n",
    "# Now it is just an object with a self containing the sensor name and the path and some colors for plotting\n",
    "processed_1 = preprocess(path, Wns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all relevant and irrelevant info from the csv file\n",
    "processed_1.Info = processed_1.get_info()\n",
    "processed_1.Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to which you want the data to ba saved. Can be the same as the rootdir\n",
    "save_to_path = rootdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_1.path.split('/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "Now I recommend going to line 134 in the function script and look for the line: \n",
    "- mousename = self.path.split('/')[-3]#[:6]\n",
    "\n",
    "the file structure should be so that self.path.split('/')[-3] will give a string with the name of the mouse. However, sometimes the name is saved in a string for example like this: \n",
    "- 'B6J2723-2024-12-05T15-57-58'\n",
    "\n",
    "If so, please add [:4]where the number is the same as the number of letters that the name consist of. The slicing my have to be different if the name for example comes at the end\n",
    "\n",
    "OR: rename the filenames to include just the mouse Id and not the date or anything else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_1.rawdata, processed_1.data, processed_1.data_seconds, processed_1.signals, processed_1.save_path = processed_1.create_basic(path_save = save_to_path)\n",
    "'''\n",
    "Here, we run the create_basic() function. This involves saving some data for later. \n",
    "- The first element is the raw-data, just meaning that it is just saved to the object\n",
    "- The second element gives the cut data, now cutting the first 15 seconds due to initial bleaching\n",
    "- The third element is just the timestamps made into seconds (rather than milliseconds)\n",
    "- The fourth elements is a df of flourescent traces only from each of the recorded exitatory wavelenghts\n",
    "- Fith element is the path created in which the preprocessed file and plots will be saved. \n",
    "    This part assumes the presence of a folder in the same location as this file named 'preprocessed' where all preprocessed data can be saved\n",
    "    If it does not exist already, there is created folders \n",
    "    named by the encloding experiment folder, the animal folder, and the time and date folder.\n",
    "    If it already exists - whatch out, whatever is stored there will be overwritten if it has the same names \n",
    "        - for example if you already preprocessed it\n",
    "    For now, this is an empty folder\n",
    "'''\n",
    "print('\\nFolder created or already exsisting:\\n', processed_1.save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_1.data.loc[processed_1.data.Input1_event == False]\n",
    "#processed_1.data.loc[processed_1.data.State == 0] #If there is an Input1_event it should be False when state is NaN or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_1.events = processed_1.extract_events()\n",
    "'''\n",
    "now we have an element 'events' containing timestamped events\n",
    "for each event there will be a _starts and a _stops and a _event\n",
    " _starts: numpy nans for all rows except at the time stamp where the event starts\n",
    " _stops: numpy nans for all rows except at the time stamp where the event stops\n",
    " _events: False whenever the event did not take place, and True while it did take place\n",
    " The event is named the same as was as it was recorded\n",
    "'''\n",
    "processed_1.events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Filtering\n",
    "Now, by running and saving the low_pass_filt() function, all the sigals are low pass filtered using a butterworth filter. This  is where the sensor comes in, as it decides the critical frequency used, which needs to be adapted to the decay time of the sensor.\n",
    "The plot that is made is of the raw trace and the filtered trace, and is also saved to the folder created above, where is can be looked at in more detail. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_1.filtered = processed_1.low_pass_filt(plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Detrending\n",
    "A double exponential fit is made to account for sources of bleaching, and this is then subtracted from the flourescence treaces to get a detreded signal.\n",
    "It plots two things: the detrended signals and the original signals along with the exponential fit, to see if it makes sense.\n",
    "Also prints the parameters used for filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_1.data_detrended, processed_1.exp_fits = processed_1.detrend(plot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### Motion correction\n",
    "There is a motion correction function that can be used. It is now set to use the 560 nm signa, because of my doubts with the relevans of the 410 nm signal as isosbestic trace. For now, I recommend not running this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_1.motion_corr = processed_1.movement_correct(plot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### Z-scoring\n",
    "Takes the median and standard deviation of the trace. Then subtracts the median from all datapoints and divides by the standard deviation. If motion correction has been run, then it does so with the motion corrected traces, if motion is set to False. Actually, it is defaulth set to False, so its not necessary, but it can also be set to True, to have a look at how it would be with the motion correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_1.zscored = processed_1.z_score(motion = False, plot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### Delta F / F\n",
    "This is a standard way of calculating the detla F over F signal, i.e. the % change in signal. I do think it is a bit weird to use the detrending exponential fit again. I have wondered if I should change it to just a linear fit to the current detrended signal. For now I do this based on the fiber photometry primer paper code: https://github.com/ThomasAkam/photometry_preprocessing/blob/master/Photometry%20data%20preprocessing.ipynb\n",
    "\n",
    "Again, 'motion' can be set to True, bu tis defaulth False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_1.deltaF_F = processed_1.get_deltaF_F(motion = False, plot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### Add crucial info\n",
    "Here, some crucial info is added that will be included in the output csv file in the end. \n",
    "This includes the mouse ID, which is currently automatically taken from the folder name. However, if the folder is not named in this way, the function will need adjustment to account for some other way of getting the mouse ID.\n",
    "The function will ask you to provide the following:\n",
    "-  Location of fluorescent protein: write something simple and consistent across different recordings, like V1 and V2M\n",
    "-  Sex of the animal (cause that could be relevant): easiest to just write F or M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_1.crucial_info = processed_1.add_crucial_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_1.Info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### Save it as a .csv files\n",
    "This function will lead to it all being saved as a csv file which can easily be read as a pandas dataframe when the data is to be analysed.\n",
    "First it is the info csv, which I for now save, but never actually use...\n",
    "Then it is the main csv file which is very useful indeed. For this one you can add Events = True to also save the events, and motion_correct = True if you have doen motion correction and want to use this.The only difference for the latter, is really that it also saved the motion corrected raw signal. Regardless, if you did use motion correction for deltaF and z-score, this is the version that will be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#again it ensures that the folder to save in already exists, since the csv must have somewhere to be\n",
    "processed_1.info_csv = processed_1.write_info_csv()\n",
    "processed_1.data_csv = processed_1.write_preprocessed_csv()\n",
    "#optional:, motion_correct = True, Onix_align =False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "### Have a look\n",
    "By importing pandas, you can now read the file, by compying the path from above and adding 'preprocessed.csv' which is the name of your new file. Sorry about the unnamed file. It can be removed. I'll do that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv(save_to_path+'/'+processed_1.mousename+'/photometry_processed/Events.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(save_to_path+'/'+processed_1.mousename+'/photometry_processed/Processed_fluorescence.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "### Mass production\n",
    "When several paths are saved in one list, we can just loop through the list and create all the files. It is  a good idea to have a look at all the saved plots anyways. Also, for now you must wait for the prompts to add the crucial info. If you prefer I can change it so that you can add that some other way, but I like this way so I can be certain that I get it right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from preprocess_functions import preprocess #preprocess is a class containing all the function, not sure why I made it a class\n",
    "#May have to specify the location of the preprocess_functions files relative to this one\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "paths = []\n",
    "rootdir = '/Volumes/RanczLab/Nora_Cohort1_training/Visual_mismatch_day1'\n",
    "for root, dirs, files in os.walk(rootdir):\n",
    "    for filename in files:\n",
    "        if filename == 'Fluorescence-unaligned.csv':\n",
    "            #if 'wakeup' in root:\n",
    "            paths.append(root)\n",
    "[print(path) for path in paths]\n",
    "\n",
    "path_save = rootdir "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "Now loop through the list of paths and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths: \n",
    "    Wns = {'470':3, '560':25, '410':3}\n",
    "    processed = preprocess(path, Wns)\n",
    "    processed.Info = processed.get_info()\n",
    "    processed.rawdata, processed.data, processed.data_seconds, processed.signals, processed.save_path = processed.create_basic(path_save = path_save)\n",
    "    processed.events = processed.extract_events()\n",
    "    processed.filtered = processed.low_pass_filt()\n",
    "    processed.data_detrended, processed.exp_fits = processed.detrend()\n",
    "    processed.motion_corr = processed.movement_correct()\n",
    "    processed.zscored = processed.z_score(motion = False)\n",
    "    processed.deltaF_F = processed.get_deltaF_F(motion = False)\n",
    "    processed.crucial_info = processed.add_crucial_info()\n",
    "\n",
    "    processed.info_csv = processed.write_info_csv()\n",
    "\n",
    "    processed.data_csv = processed.write_preprocessed_csv()#Events = True) #optional: Events = True, motion_correct = True\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
